{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JwHbFUSB2Pp",
        "outputId": "6965ca0c-9e85-4f52-b5e7-aff98f1d49a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: transformers in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.2.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: click in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\tejas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install transformers datasets nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a8IIo4wXCxw8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tejas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\tejas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "ppFIJZegfG0p",
        "outputId": "0409e38b-daf2-48e6-dc3a-969b4a467d5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to\n",
            "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "  3%|▎         | 500/14694 [09:36<3:23:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 4.0334, 'grad_norm': 5.648264408111572, 'learning_rate': 4.82986252892337e-05, 'epoch': 0.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 1000/14694 [16:51<3:34:27,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.8608, 'grad_norm': 4.26663875579834, 'learning_rate': 4.659725057846741e-05, 'epoch': 0.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1500/14694 [24:07<3:03:08,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.7953, 'grad_norm': 3.741769790649414, 'learning_rate': 4.48958758677011e-05, 'epoch': 0.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▎        | 2000/14694 [31:25<3:14:13,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.7213, 'grad_norm': 3.9264845848083496, 'learning_rate': 4.3194501156934806e-05, 'epoch': 0.82}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 2500/14694 [38:45<2:52:23,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.7028, 'grad_norm': 3.8675878047943115, 'learning_rate': 4.149312644616851e-05, 'epoch': 1.02}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 3000/14694 [46:02<2:48:20,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.4385, 'grad_norm': 5.010801315307617, 'learning_rate': 3.9791751735402204e-05, 'epoch': 1.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 3500/14694 [55:34<3:59:48,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.4163, 'grad_norm': 4.26170539855957, 'learning_rate': 3.809037702463591e-05, 'epoch': 1.43}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 4000/14694 [1:04:02<2:41:31,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.4581, 'grad_norm': 4.675246715545654, 'learning_rate': 3.638900231386961e-05, 'epoch': 1.63}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 4500/14694 [1:11:14<2:26:18,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.4097, 'grad_norm': 3.9337430000305176, 'learning_rate': 3.4687627603103305e-05, 'epoch': 1.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 5000/14694 [1:18:29<2:23:37,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.4057, 'grad_norm': 4.362245559692383, 'learning_rate': 3.298625289233701e-05, 'epoch': 2.04}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 5500/14694 [1:25:39<2:06:59,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.2051, 'grad_norm': 4.745555877685547, 'learning_rate': 3.128487818157071e-05, 'epoch': 2.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 6000/14694 [1:32:49<2:03:07,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.1994, 'grad_norm': 4.564483165740967, 'learning_rate': 2.9583503470804413e-05, 'epoch': 2.45}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 6500/14694 [1:39:58<2:05:03,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.2379, 'grad_norm': 5.0460686683654785, 'learning_rate': 2.7882128760038112e-05, 'epoch': 2.65}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 7000/14694 [1:47:11<1:52:02,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.2605, 'grad_norm': 4.659337520599365, 'learning_rate': 2.618075404927181e-05, 'epoch': 2.86}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 7500/14694 [1:54:25<1:42:05,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.1854, 'grad_norm': 4.51217794418335, 'learning_rate': 2.4479379338505513e-05, 'epoch': 3.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 8000/14694 [2:01:37<1:36:23,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.0534, 'grad_norm': 5.526889801025391, 'learning_rate': 2.2778004627739213e-05, 'epoch': 3.27}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 8500/14694 [2:08:45<1:27:31,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.0858, 'grad_norm': 4.96920919418335, 'learning_rate': 2.1076629916972915e-05, 'epoch': 3.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 9000/14694 [2:15:52<1:19:32,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.061, 'grad_norm': 4.688619613647461, 'learning_rate': 1.9375255206206618e-05, 'epoch': 3.67}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 9500/14694 [2:23:00<1:12:20,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.0761, 'grad_norm': 4.472217082977295, 'learning_rate': 1.7673880495440317e-05, 'epoch': 3.88}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 10000/14694 [2:30:10<1:07:34,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.0045, 'grad_norm': 5.782901763916016, 'learning_rate': 1.5972505784674016e-05, 'epoch': 4.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 10500/14694 [2:37:49<1:00:48,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.9538, 'grad_norm': 5.643039226531982, 'learning_rate': 1.4271131073907717e-05, 'epoch': 4.29}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 11000/14694 [2:45:02<53:11,  1.16it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.9529, 'grad_norm': 5.538005352020264, 'learning_rate': 1.256975636314142e-05, 'epoch': 4.49}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 11500/14694 [2:52:16<45:50,  1.16it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.9425, 'grad_norm': 5.63086462020874, 'learning_rate': 1.086838165237512e-05, 'epoch': 4.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 12000/14694 [2:59:26<38:16,  1.17it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.9583, 'grad_norm': 5.16098690032959, 'learning_rate': 9.16700694160882e-06, 'epoch': 4.9}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 12500/14694 [3:06:35<33:41,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.8972, 'grad_norm': 6.050135612487793, 'learning_rate': 7.465632230842522e-06, 'epoch': 5.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 13000/14694 [3:13:43<24:30,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.8427, 'grad_norm': 5.879138469696045, 'learning_rate': 5.764257520076222e-06, 'epoch': 5.31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 13500/14694 [3:20:57<16:48,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.8544, 'grad_norm': 5.3724751472473145, 'learning_rate': 4.062882809309922e-06, 'epoch': 5.51}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 14000/14694 [3:28:08<09:44,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.8741, 'grad_norm': 5.560638904571533, 'learning_rate': 2.3615080985436233e-06, 'epoch': 5.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 14500/14694 [3:35:18<02:48,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.879, 'grad_norm': 6.447165489196777, 'learning_rate': 6.601333877773241e-07, 'epoch': 5.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14694/14694 [3:38:07<00:00,  1.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 13087.0281, 'train_samples_per_second': 2.245, 'train_steps_per_second': 1.123, 'train_loss': 3.229136655845658, 'epoch': 6.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./gpt2-fine-tuned-poem\\\\tokenizer_config.json',\n",
              " './gpt2-fine-tuned-poem\\\\special_tokens_map.json',\n",
              " './gpt2-fine-tuned-poem\\\\vocab.json',\n",
              " './gpt2-fine-tuned-poem\\\\merges.txt',\n",
              " './gpt2-fine-tuned-poem\\\\added_tokens.json')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Step 1: Download the NLTK Gutenberg corpus\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "# Step 2: Load a few books from the Gutenberg corpus\n",
        "selected_books = ['blake-poems.txt', 'milton-paradise.txt ', 'whitman-leaves.txt', 'carroll-alice.txt', 'chesterton-thursday.txt', 'austen-sense.txt']  # Add/remove as needed  'carroll-alice.txt'\n",
        "corpus = \"\"\n",
        "\n",
        "for book in selected_books:\n",
        "    corpus += gutenberg.raw(book)\n",
        "\n",
        "# Save the combined corpus to a text file\n",
        "with open(\"nltk_gutenberg_poems.txt\", \"w\") as f:\n",
        "    f.write(corpus)\n",
        "\n",
        "# Step 3: Load the GPT-2 tokenizer and model\n",
        "model_name = \"gpt2\"  # Smaller GPT-2 model for Colab\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Step 4: Prepare the dataset for training\n",
        "def load_text_dataset(file_path, tokenizer, block_size=128):\n",
        "    return TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=block_size\n",
        "    )\n",
        "\n",
        "def create_data_collator(tokenizer):\n",
        "    return DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False\n",
        "    )\n",
        "\n",
        "# Load and tokenize the dataset\n",
        "train_dataset = load_text_dataset(\"nltk_gutenberg_poems.txt\", tokenizer)\n",
        "data_collator = create_data_collator(tokenizer)\n",
        "\n",
        "# Step 5: Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-fine-tuned\",  # Directory for model checkpoints\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=6,             # Number of fine-tuning epochs\n",
        "    per_device_train_batch_size=2,  # Adjust batch size based on available memory\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",           # Directory for logs\n",
        "    prediction_loss_only=True\n",
        ")\n",
        "\n",
        "# Step 6: Fine-Tune the Model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "      # Include validation dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./gpt2-fine-tuned-poem\")\n",
        "tokenizer.save_pretrained(\"./gpt2-fine-tuned-poem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYfTcTHzCKdf",
        "outputId": "5079142a-4cef-49c3-c97e-9ca80d5426e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Poem:\n",
            "Night is young man, with his mighty head on high; \n",
            "Who doth sit by in recess without watch?  Where are the lights?\" -- cried  Thee.\n",
            "\n",
            " THEE'ENDER INTRODUCTION XXXIII [Volunteers] Volume I:--Year and Night\n",
            " (from under a cloud of stars,) year after day we move.--The sky bright-side soon darkens! O moon!\" says she aloud!--[On receiving this command from Heaven.] This\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-fine-tuned-poem\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-fine-tuned-poem\")\n",
        "\n",
        "# Define a seed text\n",
        "seed_text = \"Night is young\"\n",
        "\n",
        "# Encode the input text\n",
        "input_ids = tokenizer.encode(seed_text, return_tensors='pt')\n",
        "\n",
        "# Generate text\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=100,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    repetition_penalty=2.0,\n",
        "    top_p=0.9,\n",
        "    temperature=1.0,\n",
        "    do_sample=True,\n",
        ")\n",
        "\n",
        "# Decode and print the result\n",
        "generated_poem = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"\\nGenerated Poem:\")\n",
        "print(generated_poem)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TavLJvgH4zV9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Specify the directory where the model and tokenizer are saved\n",
        "saved_model_dir = \"C:/Users/tejas/Downloads/DSAI First Sem Tejaswi/Knowledge Processing/Project/fine_tuned_gpt\"\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(saved_model_dir)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_model_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArleCXk75G5g",
        "outputId": "32158f15-cf5b-4808-8a25-1083443faa49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Text:\n",
            "Ghosts are scary,' said the Gryphon. 'They'll take a\n",
            "man like that and eat his kid: that's the sort of thing!'\n",
            "\n",
            "'But a man like that,' the Mock Turtle replied, 'would eat only half his\n",
            "children and then go back to his own party. And if they've got to eat half\n",
            "their own children again, then God-knows what they're going to do!'\n",
            "\n",
            "'You might as well call them ghosts,' the Gryphon remarked.\n",
            "\n",
            "'I'm afraid I'm not,' said the Mock Turtle. 'I should like to think\n",
            "of them as a sort of modern family. There's something striking about such\n",
            "a thing!'\n",
            "\n",
            "'I haven't the least idea,' said the Mock Turtle, 'when you first see a\n",
            "Ghost Sunday,' and he turned suddenly round to Alice. 'I've never seen a Sunday so old!'\n",
            "\n",
            "'It was only because I've never seen him,' Alice exclaimed: 'and there's nothing in his shape\n",
            "other than a very young head: he might well be a devil looking like him, if he wasn't so good\n",
            "looking.'\n",
            "\n",
            "'Come on!' said the Gryphon sharply, drawing his wand round the Gryphon's ear like a tiger's. If the\n",
            "Duchess had been as old as the turtles, the whole idea might have been taken\n",
            "very differently: if he was five or six\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the pipeline\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Generate text from seed input\n",
        "# seed_text = \"Colorful flowers\"\n",
        "# seed_text = \"Tulips are pretty\"\n",
        "seed_text= \"Ghosts are scary\"\n",
        "# seed_text = \"This world is beautiful\"\n",
        "# seed_text= \"Life is beautiful\"\n",
        "output = generator(seed_text, max_length=300, num_return_sequences=1)\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(output[0][\"generated_text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wUfeB8N05V4m",
        "outputId": "61b41929-861a-4925-ceee-0755148cfbb4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_15d01811-9d1a-4565-8c59-ca1ba5f15cc7\", \"fine_tuned_gpt.zip\", 463252938)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Compress the saved model directory\n",
        "shutil.make_archive(\"fine_tuned_gpt\", 'zip', output_dir)\n",
        "\n",
        "# Download the compressed model\n",
        "files.download(\"fine_tuned_gpt.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMD3xXCa5fHo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Texts: ['Life is beautiful to me, and I love it\\n    with all my heart.\\n\\n\\n\\n}  Song of the Sea-Tide\\n\\nSong of the sea-tide,\\nI sing the song of the tide,\\nIt is not the sea alone, it is the whole race,\\nThe whole race of men, women, cities, farms, farms of the earth.\\n\\nI do not know what it is to be a man or woman,\\nBut']\n",
            "METEOR Scores: [0.12841091492776888]\n",
            "Average METEOR Score: 0.12841091492776888\n",
            "Perplexities of Generated Texts: [3.3819446563720703]\n",
            "Average Perplexity: 3.3819446563720703\n"
          ]
        }
      ],
      "source": [
        "# Path to your fine-tuned model in Google Drive\n",
        "fine_tuned_model_path = \"C:/Users/tejas/Downloads/DSAI First Sem Tejaswi/Knowledge Processing/Project/fine_tuned_gpt\"\n",
        "\n",
        "# Import Libraries\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Fine-Tuned Model and Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(fine_tuned_model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(fine_tuned_model_path)\n",
        "\n",
        "# Normalize text for consistency\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "# Generate Text Using the Fine-Tuned Model with Beam Search\n",
        "def generate_text(seed_text, max_length=100, num_beams=5):\n",
        "    input_ids = tokenizer.encode(seed_text, return_tensors='pt')\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,  # Use beam search to increase output quality\n",
        "        no_repeat_ngram_size=3,\n",
        "        top_k=100,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# METEOR Score Calculation with Tokenization and Stemming\n",
        "def compute_meteor_score(reference, generated):\n",
        "    reference_tokens = nltk.word_tokenize(normalize_text(reference))\n",
        "    generated_tokens = nltk.word_tokenize(normalize_text(generated))\n",
        "    \n",
        "    # Optional: Apply stemming to improve matching\n",
        "    from nltk.stem import PorterStemmer\n",
        "    stemmer = PorterStemmer()\n",
        "    reference_tokens = [stemmer.stem(token) for token in reference_tokens]\n",
        "    generated_tokens = [stemmer.stem(token) for token in generated_tokens]\n",
        "    \n",
        "    return meteor_score([reference_tokens], generated_tokens)\n",
        "\n",
        "# Example Reference Texts\n",
        "reference_texts = [\n",
        "    \"Life is nice, like eating rice. The sun is bright, it gives me light. Birds fly high, way up in the sky. Flowers are cool, they grow by the pool. Life is great, don't hesitate. Unless you're late, then blame your fate. Roses are red, violets are blue, Life is beautiful, and that’s... true?\"  ]\n",
        "\n",
        "# Generate Text Using a Seed\n",
        "seed_text = \"Life is beautiful\"\n",
        "generated_texts = [generate_text(seed_text, max_length=100, num_beams=5) for _ in range(len(reference_texts))]\n",
        "\n",
        "# # Compute METEOR Scores\n",
        "# meteor_scores = [compute_meteor_score(ref, gen) for ref, gen in zip(reference_texts, generated_texts)]\n",
        "# average_meteor = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "# # Print METEOR Scores and Average METEOR Score\n",
        "# print(\"Generated Texts:\", generated_texts)\n",
        "# print(\"METEOR Scores:\", meteor_scores)\n",
        "# print(\"Average METEOR Score:\", average_meteor)\n",
        "\n",
        "# Compute METEOR Scores\n",
        "meteor_scores = [compute_meteor_score(ref, gen) for ref, gen in zip(reference_texts, generated_texts)]\n",
        "average_meteor = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "# Compute Perplexity for Each Generated Text\n",
        "perplexities = [calculate_perplexity(model, tokenizer, gen) for gen in generated_texts]\n",
        "average_perplexity = sum(perplexities) / len(perplexities)\n",
        "\n",
        "# Print Results\n",
        "print(\"Generated Texts:\", generated_texts)\n",
        "print(\"METEOR Scores:\", meteor_scores)\n",
        "print(\"Average METEOR Score:\", average_meteor)\n",
        "print(\"Perplexities of Generated Texts:\", perplexities)\n",
        "print(\"Average Perplexity:\", average_perplexity)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
